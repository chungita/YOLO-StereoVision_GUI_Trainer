"""
è¨“ç·´æ ¸å¿ƒæ¨¡çµ„
Training Core Module
è™•ç†æ‰€æœ‰è¨“ç·´ç›¸é—œçš„æ ¸å¿ƒé‚è¼¯ï¼Œå®Œå…¨ç¨ç«‹æ–¼GUI
"""

import sys
from pathlib import Path
from typing import Dict, Any, Optional, Callable
from datetime import datetime

# æ·»åŠ Codeç›®å½•åˆ°Pythonè·¯å¾„
code_dir = Path(__file__).parent.parent.parent / "Code"
if str(code_dir) not in sys.path:
    sys.path.insert(0, str(code_dir))

from Code.YOLO_standard_trainer import YOLOStandardTrainer


class TrainingCore:
    """è¨“ç·´æ ¸å¿ƒé¡ - å®Œå…¨ç¨ç«‹çš„è¨“ç·´é‚è¼¯"""
    
    def __init__(self):
        self.current_trainer = None
        self._stop_requested = False
        
    def train_with_pretrained(self, 
                            config_path: str,
                            model_path: str,
                            epochs: int = 50,
                            learning_rate: float = 0.01,
                            batch_size: int = 16,
                            imgsz: int = 640,
                            save_period: int = -1,
                            # æ•°æ®å¢å¼ºå‚æ•°
                            scale: float = 0.5,
                            mosaic: float = 1.0,
                            mixup: float = 0.0,
                            copy_paste: float = 0.0,
                            hsv_h: float = 0.015,
                            hsv_s: float = 0.7,
                            hsv_v: float = 0.4,
                            bgr: float = 0.0,
                            auto_augment: Optional[str] = None,
                            # å‡ ä½•å˜æ¢å‚æ•°
                            degrees: float = 0.0,
                            translate: float = 0.1,
                            shear: float = 0.0,
                            perspective: float = 0.0,
                            # ç¿»è½¬å’Œè£å‰ªå‚æ•°
                            flipud: float = 0.0,
                            fliplr: float = 0.5,
                            erasing: float = 0.0,
                            crop_fraction: float = 1.0,
                            # ä¼˜åŒ–å™¨å‚æ•°
                            weight_decay: float = 0.0005,
                            momentum: float = 0.937,
                            beta1: float = 0.9,
                            beta2: float = 0.999,
                            # å­¦ä¹ ç‡è°ƒåº¦å‚æ•°
                            lr_scheduler: str = 'auto',
                            lr_decay: float = 0.1,
                            warmup_epochs: int = 3,
                            warmup_momentum: float = 0.8,
                            # éªŒè¯å‚æ•°
                            val_frequency: int = 1,
                            val_iters: int = 32,
                            early_stopping_patience: int = 50,
                            early_stopping_min_delta: float = 0.001,
                            # è®¾å¤‡å‚æ•°
                            device: str = 'auto',
                            multi_gpu: bool = False,
                            gpu_memory_optimization: bool = True,
                            data_loading_optimization: bool = True,
                            # å…¶ä»–é«˜çº§å‚æ•°
                            close_mosaic: int = 10,
                            single_cls: bool = False,
                            cache: bool = False,
                            resume: bool = False,
                            workers: int = 8,
                            optimizer: str = 'auto',
                            amp: bool = True,
                            progress_callback: Optional[Callable] = None,
                            log_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨é è¨“ç·´æ¨¡å‹é€²è¡Œè¨“ç·´
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾‘
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾‘
            epochs: è¨“ç·´è¼ªæ•¸
            learning_rate: å­¸ç¿’ç‡
            batch_size: æ‰¹æ¬¡å¤§å°
            imgsz: åœ–åƒå¤§å°
            save_period: ä¿å­˜é€±æœŸ
            # æ•°æ®å¢å¼ºå‚æ•°
            scale: ç¸®æ”¾æ¯”ä¾‹
            mosaic: Mosaicæ•¸æ“šå¢å¼·
            mixup: Mixupæ•¸æ“šå¢å¼·
            copy_paste: Copy-pasteæ•¸æ“šå¢å¼·
            hsv_h: HSVè‰²ç›¸å¢å¼·åƒæ•¸
            hsv_s: HSVé£½å’Œåº¦å¢å¼·åƒæ•¸
            hsv_v: HSVæ˜åº¦å¢å¼·åƒæ•¸
            bgr: BGRé€šé“å¢å¼·åƒæ•¸
            auto_augment: è‡ªå‹•å¢å¼·ç­–ç•¥
            # å‡ ä½•å˜æ¢å‚æ•°
            degrees: æ—‹è½‰è§’åº¦
            translate: å¹³ç§»è·é›¢
            shear: å‰ªåˆ‡è§’åº¦
            perspective: é€è¦–è®Šæ›
            # ç¿»è½¬å’Œè£å‰ªå‚æ•°
            flipud: ä¸Šä¸‹ç¿»è½‰æ¦‚ç‡
            fliplr: å·¦å³ç¿»è½‰æ¦‚ç‡
            erasing: éš¨æ©Ÿæ“¦é™¤æ¦‚ç‡
            crop_fraction: è£å‰ªæ¯”ä¾‹
            # ä¼˜åŒ–å™¨å‚æ•°
            weight_decay: æ¬Šé‡è¡°æ¸›
            momentum: å‹•é‡
            beta1: Adamå„ªåŒ–å™¨Î²1åƒæ•¸
            beta2: Adamå„ªåŒ–å™¨Î²2åƒæ•¸
            # å­¦ä¹ ç‡è°ƒåº¦å‚æ•°
            lr_scheduler: å­¸ç¿’ç‡èª¿åº¦å™¨
            lr_decay: å­¸ç¿’ç‡è¡°æ¸›
            warmup_epochs: é ç†±è¼ªæ•¸
            warmup_momentum: é ç†±å‹•é‡
            # éªŒè¯å‚æ•°
            val_frequency: é©—è­‰é »ç‡
            val_iters: é©—è­‰è¿­ä»£æ¬¡æ•¸
            early_stopping_patience: æ—©åœè€å¿ƒå€¼
            early_stopping_min_delta: æ—©åœæœ€å°æ”¹å–„
            # è®¾å¤‡å‚æ•°
            device: è¨­å‚™é¸æ“‡
            multi_gpu: å¤šGPUè¨“ç·´
            gpu_memory_optimization: GPUå…§å­˜å„ªåŒ–
            data_loading_optimization: æ•¸æ“šåŠ è¼‰å„ªåŒ–
            # å…¶ä»–é«˜çº§å‚æ•°
            close_mosaic: é—œé–‰Mosaicçš„epochæ•¸
            single_cls: å–®é¡åˆ¥è¨“ç·´
            cache: æ•¸æ“šç·©å­˜
            resume: æ¢å¾©è¨“ç·´
            workers: å·¥ä½œé€²ç¨‹æ•¸
            optimizer: å„ªåŒ–å™¨é¡å‹
            amp: æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦
            progress_callback: é€²åº¦å›èª¿å‡½æ•¸
            log_callback: æ—¥èªŒå›èª¿å‡½æ•¸
            
        Returns:
            è¨“ç·´çµæœå­—å…¸
        """
        try:
            if log_callback:
                log_callback("ğŸ“¦ èª¿ç”¨æ¨™æº–è¨“ç·´å™¨æ¨¡çµ„ Calling standard trainer module...")
                log_callback(f"ğŸ“‹ é è¨“ç·´æ¨¡å¼ Pretrained mode - PT: {model_path}")
            
            # å‰µå»ºè¨“ç·´å™¨
            self.current_trainer = YOLOStandardTrainer(
                config_path=config_path,
                model_path=model_path,
                epochs=epochs,
                learning_rate=learning_rate,
                batch_size=batch_size,
                imgsz=imgsz,
                save_period=save_period,
                # æ•°æ®å¢å¼ºå‚æ•°
                scale=scale,
                mosaic=mosaic,
                mixup=mixup,
                copy_paste=copy_paste,
                hsv_h=hsv_h,
                hsv_s=hsv_s,
                hsv_v=hsv_v,
                bgr=bgr,
                auto_augment=auto_augment,
                # å‡ ä½•å˜æ¢å‚æ•°
                degrees=degrees,
                translate=translate,
                shear=shear,
                perspective=perspective,
                # ç¿»è½¬å’Œè£å‰ªå‚æ•°
                flipud=flipud,
                fliplr=fliplr,
                erasing=erasing,
                crop_fraction=crop_fraction,
                # ä¼˜åŒ–å™¨å‚æ•°
                weight_decay=weight_decay,
                momentum=momentum,
                beta1=beta1,
                beta2=beta2,
                # å­¦ä¹ ç‡è°ƒåº¦å‚æ•°
                lr_scheduler=lr_scheduler,
                lr_decay=lr_decay,
                warmup_epochs=warmup_epochs,
                warmup_momentum=warmup_momentum,
                # éªŒè¯å‚æ•°
                val_frequency=val_frequency,
                val_iters=val_iters,
                early_stopping_patience=early_stopping_patience,
                early_stopping_min_delta=early_stopping_min_delta,
                # è®¾å¤‡å‚æ•°
                device=device,
                multi_gpu=multi_gpu,
                gpu_memory_optimization=gpu_memory_optimization,
                data_loading_optimization=data_loading_optimization,
                # å…¶ä»–é«˜çº§å‚æ•°
                close_mosaic=close_mosaic,
                single_cls=single_cls,
                cache=cache,
                resume=resume,
                workers=workers,
                optimizer=optimizer,
                amp=amp
            )
            
            if log_callback:
                log_callback("ğŸš€ é–‹å§‹è¨“ç·´ï¼ˆé è¨“ç·´æ¨¡å¼ï¼‰... Starting training (Pretrained mode)...")
                log_callback(f"   è¼ªæ•¸ Epochs: {epochs}, æ‰¹æ¬¡ Batch: {batch_size}, å­¸ç¿’ç‡ LR: {learning_rate}")
            
            # åŸ·è¡Œè¨“ç·´
            results = self.current_trainer.train(
                progress_callback=progress_callback,
                log_callback=log_callback
            )
            
            return {
                'success': True,
                'results': results,
                'message': 'è¨“ç·´å®Œæˆ Training completed'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'message': f'è¨“ç·´å¤±æ•— Training failed: {str(e)}'
            }
    
    def train_with_yaml(self,
                       config_path: str,
                       yaml_path: str,
                       model_size: str = 'n',
                       epochs: int = 50,
                       learning_rate: float = 0.01,
                       batch_size: int = 16,
                       imgsz: int = 640,
                       save_period: int = -1,
                       scale: float = 0.5,
                       mosaic: float = 1.0,
                       mixup: float = 0.0,
                       copy_paste: float = 0.0,
                       hsv_h: float = 0.015,
                       hsv_s: float = 0.7,
                       hsv_v: float = 0.4,
                       bgr: float = 0.0,
                       auto_augment: Optional[str] = None,
                       degrees: float = 0.0,
                       translate: float = 0.1,
                       shear: float = 0.0,
                       perspective: float = 0.0,
                       flipud: float = 0.0,
                       fliplr: float = 0.5,
                       erasing: float = 0.0,
                       crop_fraction: float = 1.0,
                       close_mosaic: int = 10,
                       workers: int = 8,
                       optimizer: str = 'auto',
                       amp: bool = True,
                       progress_callback: Optional[Callable] = None,
                       log_callback: Optional[Callable] = None) -> Dict[str, Any]:
        """
        ä½¿ç”¨YAMLé…ç½®å¾é ­è¨“ç·´
        
        Args:
            config_path: é…ç½®æ–‡ä»¶è·¯å¾‘
            yaml_path: YAMLé…ç½®æ–‡ä»¶è·¯å¾‘
            model_size: æ¨¡å‹å¤§å° (n, s, m, l, x)
            epochs: è¨“ç·´è¼ªæ•¸
            learning_rate: å­¸ç¿’ç‡
            batch_size: æ‰¹æ¬¡å¤§å°
            imgsz: åœ–åƒå¤§å°
            save_period: ä¿å­˜é€±æœŸ
            scale: ç¸®æ”¾æ¯”ä¾‹
            mosaic: Mosaicæ•¸æ“šå¢å¼·
            mixup: Mixupæ•¸æ“šå¢å¼·
            copy_paste: Copy-pasteæ•¸æ“šå¢å¼·
            hsv_h: HSVè‰²ç›¸å¢å¼·åƒæ•¸
            hsv_s: HSVé£½å’Œåº¦å¢å¼·åƒæ•¸
            hsv_v: HSVæ˜åº¦å¢å¼·åƒæ•¸
            bgr: BGRé€šé“å¢å¼·åƒæ•¸
            auto_augment: è‡ªå‹•å¢å¼·ç­–ç•¥
            degrees: æ—‹è½‰è§’åº¦
            translate: å¹³ç§»è·é›¢
            shear: å‰ªåˆ‡è§’åº¦
            perspective: é€è¦–è®Šæ›
            flipud: ä¸Šä¸‹ç¿»è½‰æ¦‚ç‡
            fliplr: å·¦å³ç¿»è½‰æ¦‚ç‡
            erasing: éš¨æ©Ÿæ“¦é™¤æ¦‚ç‡
            crop_fraction: è£å‰ªæ¯”ä¾‹
            close_mosaic: é—œé–‰Mosaicçš„epochæ•¸
            workers: å·¥ä½œé€²ç¨‹æ•¸
            optimizer: å„ªåŒ–å™¨é¡å‹
            amp: æ˜¯å¦ä½¿ç”¨æ··åˆç²¾åº¦
            progress_callback: é€²åº¦å›èª¿å‡½æ•¸
            log_callback: æ—¥èªŒå›èª¿å‡½æ•¸
            
        Returns:
            è¨“ç·´çµæœå­—å…¸
        """
        try:
            import warnings
            warnings.filterwarnings('ignore')
            from ultralytics import YOLO
            
            if log_callback:
                log_callback(f"ğŸ“‹ é‡æ–°è¨“ç·´æ¨¡å¼ Retrain mode - YAML: {yaml_path}")
                log_callback(f"ğŸ“‹ æ¨¡å‹å¤§å° Model size: {model_size}")
            
            # æ§‹å»ºå¸¶æœ‰æ¨¡å‹å¤§å°çš„YAMLè·¯å¾‘
            base_name = Path(yaml_path).stem
            sized_yaml = f"{base_name}{model_size}.yaml"
            
            # æª¢æŸ¥å¸¶æœ‰æ¨¡å‹å¤§å°çš„YAMLæ–‡ä»¶æ˜¯å¦å­˜åœ¨
            sized_yaml_path = Path(sized_yaml)
            if sized_yaml_path.exists():
                if log_callback:
                    log_callback(f"ğŸ“‹ ä½¿ç”¨ Using: {sized_yaml}")
                model = YOLO(model=sized_yaml)
            else:
                if log_callback:
                    log_callback(f"ğŸ“‹ ä½¿ç”¨åŸºç¤æ–‡ä»¶ Using base file: {yaml_path}")
                model = YOLO(model=yaml_path)
            
            # å­˜å„²è¨“ç·´å™¨å¼•ç”¨ä»¥æ”¯æŒåœæ­¢åŠŸèƒ½
            self.current_trainer = model
            
            if log_callback:
                log_callback("ğŸš€ é–‹å§‹è¨“ç·´ï¼ˆYAMLæ¨¡å¼ï¼‰... Starting training (YAML mode)...")
                log_callback(f"   è¼ªæ•¸ Epochs: {epochs}, æ‰¹æ¬¡ Batch: {batch_size}, å­¸ç¿’ç‡ LR: {learning_rate}")
            
            # ç›´æ¥ä½¿ç”¨ ultralytics è¨“ç·´
            results = model.train(
                data=config_path,
                imgsz=imgsz,
                epochs=epochs,
                batch=batch_size,
                lr0=learning_rate,
                amp=amp,
                workers=workers,
                device='',
                optimizer=optimizer,
                close_mosaic=close_mosaic,
                resume=False,
                project='runs',
                name=self._generate_custom_model_name(config_path, yaml_path, model_size, epochs, 'retrain'),
                single_cls=False,
                cache=False,
                save_period=save_period,
                hsv_h=hsv_h,
                hsv_s=hsv_s,
                hsv_v=hsv_v,
                bgr=bgr,
                auto_augment=auto_augment,
                degrees=degrees,
                translate=translate,
                scale=scale,
                shear=shear,
                perspective=perspective,
                flipud=flipud,
                fliplr=fliplr,
                mosaic=mosaic,
                mixup=mixup,
                copy_paste=copy_paste,
                erasing=erasing,
                crop_fraction=crop_fraction
            )
            
            return {
                'success': True,
                'results': results,
                'message': 'è¨“ç·´å®Œæˆ Training completed'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': str(e),
                'message': f'è¨“ç·´å¤±æ•— Training failed: {str(e)}'
            }
    
    def stop_training(self):
        """åœæ­¢è¨“ç·´"""
        self._stop_requested = True
        
        if self.current_trainer:
            try:
                if hasattr(self.current_trainer, 'request_stop'):
                    self.current_trainer.request_stop()
            except Exception:
                pass  # éœé»˜è™•ç†
    
    def _generate_custom_model_name(self, config_path: str, model_file: str, model_size: str, epochs: int, training_mode: str) -> str:
        """ç”Ÿæˆè‡ªå®šç¾©æ¨¡å‹åç¨±
        
        æ ¼å¼: {model_name}_{channel_type}_{epochs}epochs_{timestamp}
        ä¾‹å¦‚: yolo12n_RGB_50epochs_20251212_1430
        """
        try:
            import yaml
            import re
            with open(config_path, 'r', encoding='utf-8') as f:
                dataset_config = yaml.safe_load(f)
            
            channels = dataset_config.get('channels', 3)
            channel_type = 'RGBD' if channels == 4 else 'RGB'
            
            # ç²å–æ¨¡å‹åç¨±
            if training_mode == 'retrain':
                model_name = Path(model_file).stem
                full_model_name = f"{model_name}{model_size}"  # ä¾‹å¦‚: yolo12n
            else:
                model_name = Path(model_file).stem
                full_model_name = model_name
            
            # ç§»é™¤æ¨¡å‹åç¨±ä¸­å·²æœ‰çš„é€šé“é¡å‹å¾Œç¶´ (é¿å…é‡è¤‡)
            # ä¾‹å¦‚: yolo12n_RGBD -> yolo12n, yolo12n_RGB -> yolo12n
            full_model_name = re.sub(r'_(RGBD|RGB|4ch|3ch)$', '', full_model_name, flags=re.IGNORECASE)
            
            # ç”Ÿæˆæ™‚é–“æˆ³ (æ ¼å¼: YYYYMMDD_HHMM)
            timestamp = datetime.now().strftime("%Y%m%d_%H%M")
            
            # ç”ŸæˆåŸºç¤æ¨¡å‹åç¨± (æ ¼å¼: {æ¨¡å‹å}_{é€šé“é¡å‹}_{è¼ªæ•¸}epochs_{æ™‚é–“æˆ³})
            base_custom_name = f"{full_model_name}_{channel_type}_{epochs}epochs_{timestamp}"
            
            # æª¢æŸ¥æ–‡ä»¶å¤¾æ˜¯å¦å·²å­˜åœ¨ï¼Œå¦‚æœå­˜åœ¨å‰‡æ·»åŠ åºè™Ÿ
            custom_name = self._get_unique_training_folder_name(base_custom_name)
            
            return custom_name
            
        except Exception as e:
            return 'exp'
    
    def _get_unique_training_folder_name(self, base_name: str) -> str:
        """ç”Ÿæˆå”¯ä¸€çš„è¨“ç·´æ–‡ä»¶å¤¾åç¨±ï¼Œå¦‚æœé‡è¤‡å‰‡æ·»åŠ åºè™Ÿ"""
        # æª¢æŸ¥ runs/train ç›®éŒ„æ˜¯å¦å­˜åœ¨
        runs_train_dir = Path('runs/train')
        if not runs_train_dir.exists():
            return base_name
        
        # æª¢æŸ¥åŸºç¤åç¨±æ˜¯å¦å·²å­˜åœ¨
        if not (runs_train_dir / base_name).exists():
            return base_name
        
        # å¦‚æœå­˜åœ¨ï¼Œæ·»åŠ åºè™Ÿ
        counter = 1
        while True:
            unique_name = f"{base_name}({counter})"
            if not (runs_train_dir / unique_name).exists():
                return unique_name
            counter += 1


# å…¨å±€è¨“ç·´æ ¸å¿ƒå¯¦ä¾‹
training_core = TrainingCore()
