"""
é€šç”¨å·¥ä½œçº¿ç¨‹
General Worker Thread
å¤„ç†å„ç§åå°ä»»åŠ¡çš„å·¥ä½œçº¿ç¨‹ç±»ï¼ŒåŒ…æ‹¬æ•°æ®è½¬æ¢ã€æ¨ç†å’Œè®­ç»ƒ
"""

import sys
import torch
from pathlib import Path
from datetime import datetime
from typing import Dict, Any, Optional, Callable
from PyQt5.QtCore import QThread, pyqtSignal, QMutex

# å¯¼å…¥æ•°æ®è½¬æ¢æ¨¡å—
from Code.data_converter import RGBPreprocessor, StereoPreprocessor

# æ·»åŠ Codeç›®å½•åˆ°Pythonè·¯å¾„
code_dir = Path(__file__).parent.parent.parent / "Code"
if str(code_dir) not in sys.path:
    sys.path.insert(0, str(code_dir))

# å¯¼å…¥è®­ç»ƒæ ¸å¿ƒæ¨¡å—
try:
    from gui.modules.training_engine import training_core
except ImportError:
    training_core = None


class WorkerThread(QThread):
    """é€šç”¨å·¥ä½œçº¿ç¨‹ç±» - General Worker Thread Class
    æ”¯æŒæ•°æ®è½¬æ¢ã€æ¨ç†å’Œè®­ç»ƒä»»åŠ¡
    """
    progress = pyqtSignal(str)
    finished = pyqtSignal(bool, str)
    log_message = pyqtSignal(str)
    epoch_progress = pyqtSignal(int, int, str)  # current, total, text
    
    def __init__(self, task_type, **kwargs):
        super().__init__()
        self.task_type = task_type
        self.kwargs = kwargs
        self.mutex = QMutex()
        self._stop_requested = False
        self._current_trainer = None
        
    def run(self):
        try:
            if self._stop_requested:
                return
                
            if self.task_type == "convert":
                self._convert_data()
            elif self.task_type == "inference":
                self._inference()
            elif self.task_type == "stereo_inference":
                self._stereo_inference()
            elif self.task_type == "train_pretrained":
                self._train_with_pretrained()
            elif self.task_type == "train_yaml":
                self._train_with_yaml()
            elif self.task_type == "train_stereo":
                self._train_stereo()
            else:
                raise ValueError(f"æœªçŸ¥çš„ä»»å‹™é¡å‹ Unknown task type: {self.task_type}")
            
            if not self._stop_requested:
                self.finished.emit(True, "ä»»å‹™å®Œæˆ Task completed")
        except Exception as e:
            if not self._stop_requested:
                self.finished.emit(False, str(e))
    
    def stop(self):
        """å®‰å…¨åœæ­¢çº¿ç¨‹ - Stop thread safely"""
        self._stop_requested = True
        
        # å¦‚æœæ­£åœ¨è®­ç»ƒï¼Œè¯·æ±‚è®­ç»ƒå™¨åœæ­¢
        if hasattr(self, '_current_trainer') and self._current_trainer:
            try:
                if hasattr(self._current_trainer, 'stop'):
                    self._current_trainer.stop()
                elif hasattr(self._current_trainer, 'request_stop'):
                    self._current_trainer.request_stop()
            except Exception:
                pass  # é™é»˜å¤„ç†
        
        # åœæ­¢è®­ç»ƒæ ¸å¿ƒ
        if training_core:
            try:
                training_core.stop_training()
            except Exception:
                pass
        
        # é‡Šæ”¾PyTorchå’ŒCUDAèµ„æº
        try:
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
                torch.cuda.synchronize()
        except Exception:
            # é™é»˜å¤„ç†CUDAèµ„æºé‡Šæ”¾é”™è¯¯
            pass
        
        self.quit()
        self.wait(3000)  # ç­‰å¾…3ç§’
        if self.isRunning():
            self.terminate()
            self.wait(1000)  # å†ç­‰å¾…1ç§’
    
    def _convert_data(self):
        """æ•°æ®è½¬æ¢ - Data Conversion"""
        try:
            self.progress.emit("æ­£åœ¨é–‹å§‹æ•¸æ“šè½‰æ›... Starting data conversion...")
            
            # æå–å‚æ•°
            source_path = self.kwargs['source_path']
            output_path = self.kwargs.get('output_path')
            use_depth = self.kwargs.get('use_depth', True)
            use_stereo = self.kwargs.get('use_stereo', False)
            folder_count_limit = self.kwargs.get('folder_count_limit')
            train_ratio = self.kwargs.get('train_ratio')
            val_ratio = self.kwargs.get('val_ratio')
            test_ratio = self.kwargs.get('test_ratio')
            
            # éªŒè¯æºè·¯å¾„
            if not Path(source_path).exists():
                raise FileNotFoundError(f"æºè·¯å¾‘ä¸å­˜åœ¨ Source path does not exist: {source_path}")
            
            # è¾“å‡ºè½¬æ¢æ¨¡å¼ä¿¡æ¯
            if use_stereo:
                mode_desc = "ç«‹é«”è¦–è¦ºæ•¸æ“š Stereo Vision Data"
                self.log_message.emit("ğŸ”„ é–‹å§‹ç«‹é«”è¦–è¦ºæ•¸æ“šè½‰æ›... Starting stereo data conversion...")
            elif use_depth:
                mode_desc = "4é€šé“RGBDæ•¸æ“š 4-Channel RGBD Data"
                self.log_message.emit("ğŸ”„ é–‹å§‹4é€šé“æ•¸æ“šè½‰æ›... Starting 4-channel data conversion...")
            else:
                mode_desc = "3é€šé“RGBæ•¸æ“š 3-Channel RGB Data"
                self.log_message.emit("ğŸ”„ é–‹å§‹3é€šé“æ•¸æ“šè½‰æ›... Starting 3-channel data conversion...")
            
            self.log_message.emit(f"æºè·¯å¾‘ Source: {source_path}")
            if output_path:
                self.log_message.emit(f"è¼¸å‡ºè·¯å¾‘ Output: {output_path}")
            self.log_message.emit(f"æ•¸æ“šæ¨¡å¼ Mode: {mode_desc}")
            
            # æ ¹æ®é€‰é¡¹åˆ›å»ºå¯¹åº”çš„é¢„å¤„ç†å™¨
            preprocessor_kwargs = {
                'source_path': source_path,
                'output_path': output_path,
                'folder_count_limit': folder_count_limit
            }
            
            # å¦‚æœæä¾›äº†è‡ªå®šä¹‰åˆ†å‰²æ¯”ä¾‹ï¼Œæ·»åŠ åˆ°å‚æ•°ä¸­
            if train_ratio is not None:
                preprocessor_kwargs['train_ratio'] = train_ratio
            if val_ratio is not None:
                preprocessor_kwargs['val_ratio'] = val_ratio
            if test_ratio is not None:
                preprocessor_kwargs['test_ratio'] = test_ratio
            
            if use_stereo:
                preprocessor = StereoPreprocessor(**preprocessor_kwargs)
            else:
                preprocessor_kwargs['use_depth'] = use_depth
                preprocessor = RGBPreprocessor(**preprocessor_kwargs)
            
            # å¤„ç†æ•°æ®
            preprocessor.process_all_data()
            
            self.log_message.emit("[SUCCESS] æ•¸æ“šè½‰æ›å®Œæˆ! Data conversion completed!")
            self.log_message.emit(f"[FOLDER] æ•¸æ“šé›†ä¿å­˜åœ¨ Dataset saved at: {preprocessor.output_path}")
            
            self.progress.emit("æ•¸æ“šè½‰æ›å®Œæˆ Data conversion completed")
            
        except Exception as e:
            error_msg = f"[ERROR] æ•¸æ“šè½‰æ›å¤±æ•— Data conversion failed: {str(e)}"
            self.log_message.emit(error_msg)
            self.progress.emit("æ•¸æ“šè½‰æ›å¤±æ•— Data conversion failed")
            raise e
    
    
    def _inference(self):
        """æ¨ç†å¤„ç† - Inference Processing"""
        try:
            self.progress.emit("æ­£åœ¨é–‹å§‹æ¨ç†... Starting inference...")
            self.log_message.emit("ğŸ¯ é–‹å§‹æ¨ç†è™•ç†... Starting inference processing...")
            
            # è·å–æ¨ç†å‚æ•°
            model_path = self.kwargs.get('model_path')
            data_path = self.kwargs.get('data_path')
            output_path = self.kwargs.get('output_path')
            confidence = self.kwargs.get('confidence', 0.25)
            iou_threshold = self.kwargs.get('iou_threshold', 0.45)
            max_det = self.kwargs.get('max_det', 300)
            inference_mode = self.kwargs.get('inference_mode', 'single')
            
            # éªŒè¯å‚æ•°
            if not model_path:
                raise ValueError("æ¨¡å‹è·¯å¾„ä¸èƒ½ä¸ºç©º Model path cannot be empty")
            
            if not data_path:
                raise ValueError("æ•°æ®è·¯å¾„ä¸èƒ½ä¸ºç©º Data path cannot be empty")
            
            # æ£€æµ‹è®¾å¤‡
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.log_message.emit(f"ä½¿ç”¨è®¾å¤‡ Using device: {device}")
            
            # å¯¼å…¥æ¨ç†æ¨¡å—
            try:
                from Code.yolo_inference import enhanced_inference
                self.log_message.emit("âœ… æˆåŠŸè¼‰å…¥æ¨ç†æ¨¡çµ„ Successfully loaded inference module")
            except ImportError as e:
                self.log_message.emit(f"âŒ ç„¡æ³•å°å…¥æ¨ç†æ¨¡çµ„ Failed to import inference module: {e}")
                raise e
            
            # è®¾ç½®è¾“å‡ºè·¯å¾„
            if not output_path:
                output_path = "Predict/Result"
            
            # è®°å½•æ¨ç†å‚æ•°
            self.log_message.emit(f"æ¨¡å‹ Model: {model_path}")
            self.log_message.emit(f"æ•°æ® Data: {data_path}")
            self.log_message.emit(f"è¾“å‡º Output: {output_path}")
            self.log_message.emit(f"ç½®ä¿¡åº¦ Confidence: {confidence}")
            self.log_message.emit(f"IoUé˜ˆå€¼ IoU threshold: {iou_threshold}")
            self.log_message.emit(f"æœ€å¤§æ£€æµ‹ Max detections: {max_det}")
            self.log_message.emit(f"æ¨ç†æ¨¡å¼ Inference mode: {inference_mode}")
            
            # æ‰§è¡Œæ¨ç†
            self.log_message.emit("ğŸš€ é–‹å§‹åŸ·è¡Œæ¨ç†... Starting inference execution...")
            
            results = enhanced_inference(
                model_path=model_path,
                confidence_threshold=confidence,
                device=device,
                predict_data_dir=data_path,
                iou_threshold=iou_threshold,
                max_det=max_det,
                line_width=3,
                show_labels=True,
                show_conf=True,
                show_boxes=True,
                save_txt=True,
                save_conf=True,
                save_crop=False,
                visualize=True,
                augment=False,
                agnostic_nms=False,
                retina_masks=False,
                output_format='torch',
                verbose=False,
                show=False
            )
            
            # å¤„ç†æ¨ç†ç»“æœ
            if results:
                self.log_message.emit(f"âœ… æ¨ç†å®Œæˆï¼Œè™•ç†äº† {len(results)} å€‹çµæœ")
                self.log_message.emit(f"âœ… Inference completed, processed {len(results)} results")
            else:
                self.log_message.emit("âš ï¸ æ¨ç†å®Œæˆï¼Œä½†æœªæª¢æ¸¬åˆ°ä»»ä½•ç›®æ¨™")
                self.log_message.emit("âš ï¸ Inference completed but no targets detected")
            
            self.log_message.emit(f"[FOLDER] çµæœä¿å­˜åœ¨ Results saved to: {output_path}")
            self.progress.emit("æ¨ç†å®Œæˆ Inference completed")
            
        except Exception as e:
            error_msg = f"[ERROR] æ¨ç†å¤±æ•— Inference failed: {str(e)}"
            self.log_message.emit(error_msg)
            self.progress.emit("æ¨ç†å¤±æ•— Inference failed")
            raise e
    
    def _stereo_inference(self):
        """ç«‹ä½“è§†è§‰æ¨ç†å¤„ç† - Stereo Inference Processing"""
        try:
            self.progress.emit("æ­£åœ¨é–‹å§‹ç«‹é«”è¦–è¦ºæ¨ç†... Starting stereo inference...")
            self.log_message.emit("ğŸ” é–‹å§‹ç«‹é«”è¦–è¦ºæ¨ç†è™•ç†... Starting stereo inference processing...")
            
            # è·å–æ¨ç†å‚æ•°
            model_path = self.kwargs.get('model_path')
            left_imgs = self.kwargs.get('left_imgs')
            right_imgs = self.kwargs.get('right_imgs')
            output_dir = self.kwargs.get('output_dir', 'demo_output')
            valid_iters = self.kwargs.get('valid_iters', 32)
            mixed_precision = self.kwargs.get('mixed_precision', True)
            save_numpy = self.kwargs.get('save_numpy', False)
            output_format = self.kwargs.get('output_format', 'png')  # è¼¸å‡ºæ ¼å¼
            flip_non_pfm = self.kwargs.get('flip_non_pfm', False)  # éPFMæ ¼å¼ç¿»è½‰
            
            # éªŒè¯å‚æ•°
            if not model_path:
                raise ValueError("æ¨¡å‹è·¯å¾„ä¸èƒ½ä¸ºç©º Model path cannot be empty")
            
            if not left_imgs:
                raise ValueError("å·¦å›¾åƒè·¯å¾„ä¸èƒ½ä¸ºç©º Left images path cannot be empty")
            
            if not right_imgs:
                raise ValueError("å³å›¾åƒè·¯å¾„ä¸èƒ½ä¸ºç©º Right images path cannot be empty")
            
            # æ£€æµ‹è®¾å¤‡
            device = 'cuda' if torch.cuda.is_available() else 'cpu'
            self.log_message.emit(f"ä½¿ç”¨è®¾å¤‡ Using device: {device}")
            
            # å¯¼å…¥ Code/raft_stereo_inference.py ä¸­çš„å‡½æ•°å’Œç±»
            # ç”±äºè¯¥æ¨¡å—åŒ…å«å®Œæ•´çš„æ¨¡å‹å®ç°ï¼Œæˆ‘ä»¬éœ€è¦å¯¼å…¥å®ƒ
            project_root = Path(__file__).parent.parent.parent
            inference_module_path = project_root / "Code" / "raft_stereo_inference.py"
            
            if not inference_module_path.exists():
                raise FileNotFoundError(f"æ‰¾ä¸åˆ°ç«‹é«”è¦–è¦ºæ¨ç†æ¨¡çµ„æ–‡ä»¶: {inference_module_path}")
            
            # åŠ¨æ€å¯¼å…¥æ¨ç†æ¨¡å—
            import importlib.util
            spec = importlib.util.spec_from_file_location("raft_stereo_inference", inference_module_path)
            inference_module = importlib.util.module_from_spec(spec)
            spec.loader.exec_module(inference_module)
            
            self.log_message.emit("âœ… æˆåŠŸè¼‰å…¥ç«‹é«”è¦–è¦ºæ¨ç†æ¨¡çµ„ Successfully loaded stereo inference module")
            
            # åˆ›å»ºå‚æ•°å¯¹è±¡
            from argparse import Namespace
            args = Namespace(
                restore_ckpt=model_path,
                save_numpy=save_numpy,
                left_imgs=left_imgs,
                right_imgs=right_imgs,
                output_directory=output_dir,
                mixed_precision=mixed_precision,
                valid_iters=valid_iters,
                hidden_dims=[128]*3,
                corr_implementation="alt",
                shared_backbone=False,
                corr_levels=4,
                corr_radius=4,
                n_downsample=2,
                context_norm="batch",
                slow_fast_gru=False,
                n_gru_layers=3,
                output_format=output_format,  # è¼¸å‡ºæ ¼å¼é¸é …
                flip_non_pfm=flip_non_pfm  # éPFMæ ¼å¼ç¿»è½‰é¸é …
            )
            
            # è®°å½•æ¨ç†å‚æ•°
            self.log_message.emit(f"æ¨¡å‹ Model: {Path(model_path).name}")
            self.log_message.emit(f"å·¦åœ–åƒ Left images: {left_imgs}")
            self.log_message.emit(f"å³åœ–åƒ Right images: {right_imgs}")
            self.log_message.emit(f"è¼¸å‡ºç›®éŒ„ Output directory: {output_dir}")
            self.log_message.emit(f"è¿­ä»£æ¬¡æ•¸ Iterations: {valid_iters}")
            self.log_message.emit(f"æ··åˆç²¾åº¦ Mixed precision: {'å•Ÿç”¨' if mixed_precision else 'ç¦ç”¨'}")
            
            # æ£€æŸ¥å›¾åƒæ–‡ä»¶
            import glob
            left_files = sorted(glob.glob(left_imgs, recursive=True))
            right_files = sorted(glob.glob(right_imgs, recursive=True))
            
            if not left_files:
                raise FileNotFoundError(f"æœªæ‰¾åˆ°å·¦åœ–åƒ No left images found: {left_imgs}")
            
            if not right_files:
                raise FileNotFoundError(f"æœªæ‰¾åˆ°å³åœ–åƒ No right images found: {right_imgs}")
            
            num_pairs = min(len(left_files), len(right_files))
            self.log_message.emit(f"æ‰¾åˆ° {len(left_files)} å¼µå·¦åœ–åƒå’Œ {len(right_files)} å¼µå³åœ–åƒ")
            self.log_message.emit(f"Found {len(left_files)} left images and {len(right_files)} right images")
            self.log_message.emit(f"å°‡è™•ç† {num_pairs} å°åœ–åƒ Will process {num_pairs} image pairs")
            
            # æ‰§è¡Œæ¨ç†
            self.log_message.emit("ğŸš€ é–‹å§‹åŸ·è¡Œç«‹é«”è¦–è¦ºæ¨ç†... Starting stereo inference execution...")
            
            # è°ƒç”¨ raft_stereo_inference.py ä¸­çš„ demo å‡½æ•°
            inference_module.demo(args)
            
            self.log_message.emit(f"âœ… ç«‹é«”è¦–è¦ºæ¨ç†å®Œæˆï¼è™•ç†äº† {num_pairs} å°åœ–åƒ")
            self.log_message.emit(f"âœ… Stereo inference completed! Processed {num_pairs} image pairs")
            self.log_message.emit(f"[FOLDER] çµæœä¿å­˜åœ¨ Results saved to: {output_dir}")
            self.progress.emit(f"ç«‹é«”è¦–è¦ºæ¨ç†å®Œæˆ Stereo inference completed - {num_pairs} pairs")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            error_msg = f"[ERROR] ç«‹é«”è¦–è¦ºæ¨ç†å¤±æ•— Stereo inference failed: {str(e)}"
            self.log_message.emit(error_msg)
            self.log_message.emit(f"è©³ç´°éŒ¯èª¤ä¿¡æ¯ Detailed error:\n{error_detail}")
            self.progress.emit("ç«‹é«”è¦–è¦ºæ¨ç†å¤±æ•— Stereo inference failed")
            raise e
    
    def _train_with_pretrained(self):
        """ä½¿ç”¨é è¨“ç·´æ¨¡å‹è¨“ç·´ - Train with pretrained model"""
        if not training_core:
            raise ImportError("è¨“ç·´æ ¸å¿ƒæ¨¡çµ„æœªæ‰¾åˆ° Training core module not found")
            
        try:
            self.progress.emit("æ­£åœ¨é–‹å§‹æ¨¡å‹è¨“ç·´... Starting model training...")
            self.log_message.emit("ğŸ¯ é–‹å§‹æ¨¡å‹è¨“ç·´... Starting model training...")
            
            # æå–åƒæ•¸
            config_path = self.kwargs['config_path']
            model_file = self.kwargs.get('model_file')
            epochs = self.kwargs.get('epochs', 50)
            learning_rate = self.kwargs.get('learning_rate', 0.001)
            batch_size = self.kwargs.get('batch_size', 16)
            imgsz = self.kwargs.get('imgsz', 640)
            save_period = self.kwargs.get('save_period', 10)
            
            # æ•°æ®å¢å¼ºå‚æ•°
            scale = self.kwargs.get('scale', 0.5)
            mosaic = self.kwargs.get('mosaic', 1.0)
            mixup = self.kwargs.get('mixup', 0.0)
            copy_paste = self.kwargs.get('copy_paste', 0.0)
            hsv_h = self.kwargs.get('hsv_h', 0.015)
            hsv_s = self.kwargs.get('hsv_s', 0.7)
            hsv_v = self.kwargs.get('hsv_v', 0.4)
            bgr = self.kwargs.get('bgr', 0.0)
            auto_augment = self.kwargs.get('auto_augment', None)
            
            # å‡ ä½•å˜æ¢å‚æ•°
            degrees = self.kwargs.get('degrees', 0.0)
            translate = self.kwargs.get('translate', 0.1)
            shear = self.kwargs.get('shear', 0.0)
            perspective = self.kwargs.get('perspective', 0.0)
            
            # ç¿»è½¬å’Œè£å‰ªå‚æ•°
            flipud = self.kwargs.get('flipud', 0.0)
            fliplr = self.kwargs.get('fliplr', 0.5)
            erasing = self.kwargs.get('erasing', 0.0)
            crop_fraction = self.kwargs.get('crop_fraction', 1.0)
            
            # ä¼˜åŒ–å™¨å‚æ•°
            weight_decay = self.kwargs.get('weight_decay', 0.0005)
            momentum = self.kwargs.get('momentum', 0.937)
            beta1 = self.kwargs.get('beta1', 0.9)
            beta2 = self.kwargs.get('beta2', 0.999)
            
            # å­¦ä¹ ç‡è°ƒåº¦å‚æ•°
            lr_scheduler = self.kwargs.get('lr_scheduler', 'auto')
            lr_decay = self.kwargs.get('lr_decay', 0.1)
            warmup_epochs = self.kwargs.get('warmup_epochs', 3)
            warmup_momentum = self.kwargs.get('warmup_momentum', 0.8)
            
            # éªŒè¯å‚æ•°
            val_frequency = self.kwargs.get('val_frequency', 1)
            val_iters = self.kwargs.get('val_iters', 32)
            early_stopping_patience = self.kwargs.get('early_stopping_patience', 50)
            early_stopping_min_delta = self.kwargs.get('early_stopping_min_delta', 0.001)
            
            # è®¾å¤‡å‚æ•°
            device = self.kwargs.get('device', 'auto')
            multi_gpu = self.kwargs.get('multi_gpu', False)
            gpu_memory_optimization = self.kwargs.get('gpu_memory_optimization', True)
            data_loading_optimization = self.kwargs.get('data_loading_optimization', True)
            
            # å…¶ä»–é«˜çº§å‚æ•°
            close_mosaic = self.kwargs.get('close_mosaic', 10)
            single_cls = self.kwargs.get('single_cls', False)
            cache = self.kwargs.get('cache', False)
            resume = self.kwargs.get('resume', False)
            workers = self.kwargs.get('workers', 8)
            optimizer = self.kwargs.get('optimizer', 'auto')
            amp = self.kwargs.get('amp', True)
            
            # å®šç¾©å›èª¿å‡½æ•¸
            def progress_callback(message):
                self.progress.emit(message)
                self.log_message.emit(message)
            
            def log_callback(message):
                self.log_message.emit(message)
            
            # èª¿ç”¨è¨“ç·´æ ¸å¿ƒ
            result = training_core.train_with_pretrained(
                config_path=config_path,
                model_path=model_file,
                epochs=epochs,
                learning_rate=learning_rate,
                batch_size=batch_size,
                imgsz=imgsz,
                save_period=save_period,
                # æ•°æ®å¢å¼ºå‚æ•°
                scale=scale,
                mosaic=mosaic,
                mixup=mixup,
                copy_paste=copy_paste,
                hsv_h=hsv_h,
                hsv_s=hsv_s,
                hsv_v=hsv_v,
                bgr=bgr,
                auto_augment=auto_augment,
                # å‡ ä½•å˜æ¢å‚æ•°
                degrees=degrees,
                translate=translate,
                shear=shear,
                perspective=perspective,
                # ç¿»è½¬å’Œè£å‰ªå‚æ•°
                flipud=flipud,
                fliplr=fliplr,
                erasing=erasing,
                crop_fraction=crop_fraction,
                # ä¼˜åŒ–å™¨å‚æ•°
                weight_decay=weight_decay,
                momentum=momentum,
                beta1=beta1,
                beta2=beta2,
                # å­¦ä¹ ç‡è°ƒåº¦å‚æ•°
                lr_scheduler=lr_scheduler,
                lr_decay=lr_decay,
                warmup_epochs=warmup_epochs,
                warmup_momentum=warmup_momentum,
                # éªŒè¯å‚æ•°
                val_frequency=val_frequency,
                val_iters=val_iters,
                early_stopping_patience=early_stopping_patience,
                early_stopping_min_delta=early_stopping_min_delta,
                # è®¾å¤‡å‚æ•°
                device=device,
                multi_gpu=multi_gpu,
                gpu_memory_optimization=gpu_memory_optimization,
                data_loading_optimization=data_loading_optimization,
                # å…¶ä»–é«˜çº§å‚æ•°
                close_mosaic=close_mosaic,
                single_cls=single_cls,
                cache=cache,
                resume=resume,
                workers=workers,
                optimizer=optimizer,
                amp=amp,
                progress_callback=progress_callback,
                log_callback=log_callback
            )
            
            if result['success']:
                self.log_message.emit("[SUCCESS] è¨“ç·´å®Œæˆ! Training completed!")
                self.progress.emit("è¨“ç·´å®Œæˆ Training completed")
            else:
                raise Exception(result['message'])
                
        except Exception as e:
            error_msg = f"[ERROR] è¨“ç·´å¤±æ•— Training failed: {str(e)}"
            self.log_message.emit(error_msg)
            self.progress.emit("è¨“ç·´å¤±æ•— Training failed")
            raise e
    
    def _train_with_yaml(self):
        """ä½¿ç”¨YAMLé…ç½®å¾é ­è¨“ç·´ - Train from scratch with YAML config"""
        if not training_core:
            raise ImportError("è¨“ç·´æ ¸å¿ƒæ¨¡çµ„æœªæ‰¾åˆ° Training core module not found")
            
        try:
            self.progress.emit("æ­£åœ¨é–‹å§‹æ¨¡å‹è¨“ç·´... Starting model training...")
            self.log_message.emit("ğŸ¯ é–‹å§‹æ¨¡å‹è¨“ç·´... Starting model training...")
            
            # æå–åƒæ•¸
            config_path = self.kwargs['config_path']
            model_file = self.kwargs.get('model_file')
            model_size = self.kwargs.get('model_size', 'n')
            epochs = self.kwargs.get('epochs', 50)
            learning_rate = self.kwargs.get('learning_rate', 0.001)
            batch_size = self.kwargs.get('batch_size', 16)
            imgsz = self.kwargs.get('imgsz', 640)
            save_period = self.kwargs.get('save_period', -1)
            scale = self.kwargs.get('scale', 0.5)
            mosaic = self.kwargs.get('mosaic', 1.0)
            mixup = self.kwargs.get('mixup', 0.0)
            copy_paste = self.kwargs.get('copy_paste', 0.0)
            hsv_h = self.kwargs.get('hsv_h', 0.015)
            hsv_s = self.kwargs.get('hsv_s', 0.7)
            hsv_v = self.kwargs.get('hsv_v', 0.4)
            bgr = self.kwargs.get('bgr', 0.0)
            auto_augment = self.kwargs.get('auto_augment', None)
            degrees = self.kwargs.get('degrees', 0.0)
            translate = self.kwargs.get('translate', 0.1)
            shear = self.kwargs.get('shear', 0.0)
            perspective = self.kwargs.get('perspective', 0.0)
            flipud = self.kwargs.get('flipud', 0.0)
            fliplr = self.kwargs.get('fliplr', 0.5)
            erasing = self.kwargs.get('erasing', 0.0)
            crop_fraction = self.kwargs.get('crop_fraction', 1.0)
            close_mosaic = self.kwargs.get('close_mosaic', 10)
            workers = self.kwargs.get('workers', 8)
            optimizer = self.kwargs.get('optimizer', 'auto')
            amp = self.kwargs.get('amp', True)
            
            # å®šç¾©å›èª¿å‡½æ•¸
            def progress_callback(message):
                self.progress.emit(message)
                self.log_message.emit(message)
            
            def log_callback(message):
                self.log_message.emit(message)
            
            # èª¿ç”¨è¨“ç·´æ ¸å¿ƒ
            result = training_core.train_with_yaml(
                config_path=config_path,
                yaml_path=model_file,
                model_size=model_size,
                epochs=epochs,
                learning_rate=learning_rate,
                batch_size=batch_size,
                imgsz=imgsz,
                save_period=save_period,
                scale=scale,
                mosaic=mosaic,
                mixup=mixup,
                copy_paste=copy_paste,
                hsv_h=hsv_h,
                hsv_s=hsv_s,
                hsv_v=hsv_v,
                bgr=bgr,
                auto_augment=auto_augment,
                degrees=degrees,
                translate=translate,
                shear=shear,
                perspective=perspective,
                flipud=flipud,
                fliplr=fliplr,
                erasing=erasing,
                crop_fraction=crop_fraction,
                close_mosaic=close_mosaic,
                workers=workers,
                optimizer=optimizer,
                amp=amp,
                progress_callback=progress_callback,
                log_callback=log_callback
            )
            
            if result['success']:
                self.log_message.emit("[SUCCESS] è¨“ç·´å®Œæˆ! Training completed!")
                self.progress.emit("è¨“ç·´å®Œæˆ Training completed")
            else:
                raise Exception(result['message'])
                
        except Exception as e:
            error_msg = f"[ERROR] è¨“ç·´å¤±æ•— Training failed: {str(e)}"
            self.log_message.emit(error_msg)
            self.progress.emit("è¨“ç·´å¤±æ•— Training failed")
            raise e
    
    def _train_stereo(self):
        """ç«‹é«”è¦–è¦ºè¨“ç·´ - Stereo Vision Training"""
        try:
            self.progress.emit("æ­£åœ¨é–‹å§‹ç«‹é«”è¦–è¦ºè¨“ç·´... Starting stereo vision training...")
            self.log_message.emit("ğŸ¯ é–‹å§‹ç«‹é«”è¦–è¦ºè¨“ç·´... Starting stereo vision training...")
            
            # æå–åŸºæœ¬åƒæ•¸
            dataset_path = self.kwargs['dataset_path']
            model_name = self.kwargs.get('model_name', 'raftstereo-sceneflow.pth')
            batch_size = self.kwargs.get('batch_size', 6)
            # æ”¯æŒnum_stepså’Œepochsï¼ˆå‘åå…¼å®¹ï¼‰
            num_steps = self.kwargs.get('num_steps')
            if num_steps is None:
                # å‘åå…¼å®¹ï¼šå¦‚æœæä¾›äº†epochsï¼Œè½¬æ¢ä¸ºnum_steps
                epochs = self.kwargs.get('epochs', 100)
                num_steps = epochs * 1000
            output_dir = self.kwargs.get('output_dir', 'checkpoints')
            
            # æå–é«˜ç´šåƒæ•¸
            train_iters = self.kwargs.get('train_iters', 16)
            valid_iters = self.kwargs.get('valid_iters', 32)
            corr_implementation = self.kwargs.get('corr_implementation', 'reg')
            mixed_precision = self.kwargs.get('mixed_precision', False)
            n_downsample = self.kwargs.get('n_downsample', 2)
            corr_levels = self.kwargs.get('corr_levels', 4)
            corr_radius = self.kwargs.get('corr_radius', 4)
            n_gru_layers = self.kwargs.get('n_gru_layers', 3)
            learning_rate = self.kwargs.get('learning_rate', 0.0002)
            weight_decay = self.kwargs.get('weight_decay', 0.00001)
            
            # ç²å– image_size åƒæ•¸
            # æ³¨æ„ï¼šimage_size ç”¨æ–¼è¨˜éŒ„ç›®çš„ï¼Œå¯¦éš›è¨“ç·´ä¸­ä¸ä½¿ç”¨è£å‰ªï¼ˆä¿æŒåŸå§‹åœ–åƒå°ºå¯¸ï¼‰
            # GUI å‚³éçš„æ˜¯ [width, height]ï¼Œéœ€è¦è½‰æ›ç‚º TrainingConfig æœŸæœ›çš„ (height, width)
            image_size_raw = self.kwargs.get('image_size', [320, 720])
            if isinstance(image_size_raw, list) and len(image_size_raw) == 2:
                # GUI æ ¼å¼æ˜¯ [width, height]ï¼Œè½‰æ›ç‚º (height, width)
                image_size = [image_size_raw[1], image_size_raw[0]]  # [height, width]
            else:
                image_size = [320, 720]  # é»˜èªå€¼ (height, width)
            
            # æ³¨æ„ï¼šcrop_size è¨­ç½®ç‚º Noneï¼Œä»¥ä¿æŒåŸå§‹åœ–åƒå°ºå¯¸
            # é€™é¿å…äº†ç•¶æ•¸æ“šé›†åœ–åƒå°æ–¼è£å‰ªå°ºå¯¸æ™‚çš„éŒ¯èª¤
            
            # æå– hidden_dims åƒæ•¸
            hidden_dims_raw = self.kwargs.get('hidden_dims')
            if hidden_dims_raw:
                if isinstance(hidden_dims_raw, str):
                    # å¦‚æœæ˜¯å­—ç¬¦ä¸²æ ¼å¼ "128x128x128 (é»˜èª)"ï¼Œè§£æå®ƒ
                    try:
                        dims_part = hidden_dims_raw.split('(')[0].strip()
                        hidden_dims = [int(d) for d in dims_part.split('x')]
                    except:
                        hidden_dims = [128, 128, 128]
                elif isinstance(hidden_dims_raw, list):
                    hidden_dims = hidden_dims_raw
                else:
                    hidden_dims = [128, 128, 128]
            else:
                # æ ¹æ“š n_gru_layers ç”Ÿæˆé»˜èªå€¼
                hidden_dims = [128] * n_gru_layers
            
            # å¢å»£åƒæ•¸
            spatial_scale_min = self.kwargs.get('spatial_scale_min', -0.2)
            spatial_scale_max = self.kwargs.get('spatial_scale_max', 0.4)
            saturation_min = self.kwargs.get('saturation_min', 0.0)
            saturation_max = self.kwargs.get('saturation_max', 1.4)
            gamma_min = self.kwargs.get('gamma_min', 0.8)
            gamma_max = self.kwargs.get('gamma_max', 1.2)
            
            # è™•ç† do_flip åƒæ•¸ï¼šå°‡ "ç„¡ None" è½‰æ›ç‚º None
            do_flip_raw = self.kwargs.get('do_flip', 'ç„¡ None')
            if do_flip_raw in ['ç„¡ None', 'None', 'ç„¡', None, False]:
                do_flip = None
            else:
                do_flip = do_flip_raw
            
            noyjitter = self.kwargs.get('noyjitter', False)
            
            # è¨˜éŒ„è¨“ç·´åƒæ•¸
            self.log_message.emit(f"ğŸš€ ç«‹é«”è¦–è¦ºè¨“ç·´åƒæ•¸:")
            self.log_message.emit(f"   æ•¸æ“šé›†: {dataset_path}")
            self.log_message.emit(f"   é è¨“ç·´æ¨¡å‹: {model_name}")
            self.log_message.emit(f"   è¨“ç·´åƒæ•¸: æ­¥æ•¸={num_steps}, æ‰¹æ¬¡={batch_size}")
            self.log_message.emit(f"   è¿­ä»£åƒæ•¸: è¨“ç·´={train_iters}, é©—è­‰={valid_iters}")
            self.log_message.emit(f"   åœ–åƒå°ºå¯¸: {image_size[0]}x{image_size[1]} (height x width)")
            self.log_message.emit(f"   ç›¸é—œå¯¦ç¾: {corr_implementation}")
            self.log_message.emit(f"   æ¨¡å‹æ¶æ§‹: n_downsample={n_downsample}, corr_levels={corr_levels}, corr_radius={corr_radius}")
            self.log_message.emit(f"   GRUå±¤æ•¸: {n_gru_layers}, Hidden Dims: {hidden_dims}")
            self.log_message.emit(f"   å„ªåŒ–é¸é …: æ··åˆç²¾åº¦={mixed_precision}, å­¸ç¿’ç‡={learning_rate}, æ¬Šé‡è¡°æ¸›={weight_decay}")
            
            # å°å…¥å¿…è¦çš„æ¨¡çµ„
            try:
                # ç¢ºä¿ Code ç›®éŒ„åœ¨ sys.path ä¸­
                if str(code_dir) not in sys.path:
                    sys.path.insert(0, str(code_dir))
                
                # ç›´æ¥å°å…¥ï¼Œå› ç‚º Code ç›®éŒ„å·²åœ¨ sys.path ä¸­
                import importlib.util
                trainer_path = code_dir / "raft_stereo_trainer.py"
                if not trainer_path.exists():
                    raise FileNotFoundError(f"æ‰¾ä¸åˆ°è¨“ç·´å™¨æ–‡ä»¶: {trainer_path}")
                
                spec = importlib.util.spec_from_file_location("raft_stereo_trainer", trainer_path)
                raft_stereo_module = importlib.util.module_from_spec(spec)
                spec.loader.exec_module(raft_stereo_module)
                RAFTStereoTrainer = raft_stereo_module.RAFTStereoTrainer
                
                from config.config import TrainingConfig
                self.log_message.emit("âœ… æˆåŠŸè¼‰å…¥ç«‹é«”è¦–è¦ºè¨“ç·´æ¨¡çµ„ Successfully loaded stereo training modules")
            except Exception as e:
                import traceback
                error_detail = traceback.format_exc()
                self.log_message.emit(f"âŒ ç„¡æ³•å°å…¥ç«‹é«”è¦–è¦ºè¨“ç·´æ¨¡çµ„ Failed to import stereo training modules: {e}")
                self.log_message.emit(f"è©³ç´°éŒ¯èª¤ä¿¡æ¯ Detailed error: {error_detail}")
                raise e
            
            # å‰µå»ºå¸¶æ™‚é–“æˆ³çš„è¼¸å‡ºè³‡æ–™å¤¾
            from datetime import datetime
            timestamp = datetime.now().strftime("%Y%m%dT%H%M")
            output_folder = f"runs/raft_stereo_{timestamp}"
            import os
            os.makedirs(output_folder, exist_ok=True)
            
            self.log_message.emit(f"å‰µå»ºè¼¸å‡ºè³‡æ–™å¤¾: {output_folder}")
            self.log_message.emit(f"Created output folder: {output_folder}")
            
            # æ§‹å»ºé è¨“ç·´æ¨¡å‹è·¯å¾‘
            restore_ckpt = None
            if model_name:
                # æª¢æŸ¥æ¨¡å‹æ–‡ä»¶æ˜¯å¦å­˜åœ¨
                model_paths = [
                    Path("Model_file/Stereo_Vision") / model_name,
                    Path("Model_file/PTH_File") / model_name,  # å‘å¾Œå…¼å®¹èˆŠç›®éŒ„
                    Path("Model_file") / model_name,
                    Path(model_name),  # å¦‚æœæä¾›çš„æ˜¯å®Œæ•´è·¯å¾‘
                ]
                
                for mp in model_paths:
                    if mp.exists():
                        restore_ckpt = str(mp.absolute())
                        self.log_message.emit(f"âœ… æ‰¾åˆ°é è¨“ç·´æ¨¡å‹: {restore_ckpt}")
                        break
                
                if restore_ckpt is None:
                    self.log_message.emit(f"âš ï¸ è­¦å‘Š: æœªæ‰¾åˆ°é è¨“ç·´æ¨¡å‹ {model_name}ï¼Œå°‡å¾é ­é–‹å§‹è¨“ç·´")
                    self.log_message.emit(f"âš ï¸ Warning: Pretrained model {model_name} not found, training from scratch")
            
            # å‰µå»ºè¨“ç·´é…ç½®
            # æ³¨æ„ï¼šimage_size åƒ…ç”¨æ–¼è¨˜éŒ„ï¼Œå¯¦éš›è¨“ç·´ä½¿ç”¨åŸå§‹åœ–åƒå°ºå¯¸ï¼ˆä¸è£å‰ªï¼‰
            config = TrainingConfig(
                name=f"raft-stereo-{timestamp}",
                train_datasets=['drone'],
                dataset_root=dataset_path,
                batch_size=batch_size,
                num_steps=num_steps,
                train_iters=train_iters,
                valid_iters=valid_iters,
                lr=learning_rate,
                wdecay=weight_decay,
                image_size=tuple(image_size),  # ç¢ºä¿æ˜¯å…ƒçµ„æ ¼å¼ (height, width)ï¼Œä½†ä¸ç”¨æ–¼è£å‰ª
                corr_implementation=corr_implementation,
                mixed_precision=mixed_precision,
                n_downsample=n_downsample,
                corr_levels=corr_levels,
                corr_radius=corr_radius,
                n_gru_layers=n_gru_layers,
                hidden_dims=hidden_dims,  # æ·»åŠ  hidden_dims åƒæ•¸
                spatial_scale=(spatial_scale_min, spatial_scale_max),
                saturation_range=[saturation_min, saturation_max] if (saturation_min != 0.0 or saturation_max != 1.4) else None,
                img_gamma=[gamma_min, gamma_max] if (gamma_min != 0.8 or gamma_max != 1.2) else None,
                do_flip=do_flip,  # å·²åœ¨å‰é¢è™•ç†éï¼Œç›´æ¥ä½¿ç”¨
                noyjitter=noyjitter,
                output_dir=output_folder,
                restore_ckpt=restore_ckpt
            )
            
            self.log_message.emit(f"ğŸ“‹ é…ç½®è©³æƒ…:")
            self.log_message.emit(f"   image_size: {config.image_size} (è¨˜éŒ„ç”¨é€”ï¼Œä¸è£å‰ª)")
            self.log_message.emit(f"   spatial_scale: {config.spatial_scale}")
            self.log_message.emit(f"   å¯¦éš›è¨“ç·´å°‡ä½¿ç”¨åŸå§‹åœ–åƒå°ºå¯¸ï¼ˆç„¡è£å‰ªï¼‰")
            
            # é©—è­‰é…ç½®
            if not config.validate():
                self.log_message.emit("é…ç½®é©—è­‰å¤±æ•—ï¼Œè«‹æª¢æŸ¥åƒæ•¸è¨­ç½®")
                self.log_message.emit("Configuration validation failed, please check parameters")
                raise ValueError("é…ç½®é©—è­‰å¤±æ•— Configuration validation failed")
            
            self.log_message.emit("æº–å‚™é–‹å§‹è¨“ç·´...")
            self.log_message.emit("Prepare to start training...")
            self.log_message.emit(f"ä½¿ç”¨é…ç½®: {config.name}")
            self.log_message.emit(f"Using configuration: {config.name}")
            if restore_ckpt:
                self.log_message.emit(f"é è¨“ç·´æ¨¡å‹: {restore_ckpt}")
                self.log_message.emit(f"Pretrained model: {restore_ckpt}")
            self.log_message.emit("-" * 50)
            
            # è¨­ç½®æ—¥èªŒ
            import logging
            logging.basicConfig(level=logging.INFO,
                              format='%(asctime)s %(levelname)-8s [%(filename)s:%(lineno)d] %(message)s')
            
            # æª¢æŸ¥åœæ­¢è«‹æ±‚
            if self._stop_requested:
                self.log_message.emit("è¨“ç·´å·²å–æ¶ˆ Training cancelled")
                return
            
            # å‰µå»ºè¨“ç·´å™¨ä¸¦åŸ·è¡Œè¨“ç·´
            self.log_message.emit("æ­£åœ¨åˆå§‹åŒ–è¨“ç·´å™¨... Initializing trainer...")
            trainer = RAFTStereoTrainer(config)
            self._current_trainer = trainer  # ä¿å­˜è¨“ç·´å™¨å¼•ç”¨ä»¥ä¾¿åœæ­¢
            self.log_message.emit("âœ… è¨“ç·´å™¨åˆå§‹åŒ–å®Œæˆ Trainer initialized")
            
            # æª¢æŸ¥åœæ­¢è«‹æ±‚
            if self._stop_requested:
                self.log_message.emit("è¨“ç·´å·²å–æ¶ˆ Training cancelled")
                return
            
            self.log_message.emit("ğŸš€ é–‹å§‹åŸ·è¡Œè¨“ç·´... Starting training...")
            
            # å‰µå»ºé€²åº¦å›èª¿å‡½æ•¸
            def progress_callback(current_step, total_steps, message):
                """é€²åº¦å›èª¿å‡½æ•¸"""
                if self._stop_requested:
                    return  # å¦‚æœè«‹æ±‚åœæ­¢ï¼Œä¸å†æ›´æ–°é€²åº¦
                # ç™¼é€é€²åº¦æ¶ˆæ¯ï¼ˆåŒ…å«æ­¥æ•¸ä¿¡æ¯ï¼Œç”¨æ–¼è§£æï¼‰
                progress_msg = f"Step {current_step}/{total_steps}: {message}"
                self.progress.emit(progress_msg)
                self.epoch_progress.emit(current_step, total_steps, message)
            
            # åŸ·è¡Œè¨“ç·´ï¼Œå‚³éé€²åº¦å›èª¿
            result_path = trainer.train(progress_callback=progress_callback)
            
            self.log_message.emit("-" * 50)
            self.log_message.emit("è¨“ç·´å®Œæˆï¼")
            self.log_message.emit("Training completed!")
            self.log_message.emit(f"æ¨¡å‹ä¿å­˜è·¯å¾‘: {result_path}")
            self.log_message.emit(f"Model saved to: {result_path}")
            self.log_message.emit(f"å®Œæ•´çš„è¨“ç·´è¼¸å‡ºä½æ–¼ Complete training output located at: {output_folder}")
            
            self.log_message.emit("[SUCCESS] ç«‹é«”è¦–è¦ºè¨“ç·´å®Œæˆ! Stereo vision training completed!")
            self.progress.emit("ç«‹é«”è¦–è¦ºè¨“ç·´å®Œæˆ Stereo vision training completed")
            
        except Exception as e:
            import traceback
            error_detail = traceback.format_exc()
            error_msg = f"[ERROR] ç«‹é«”è¦–è¦ºè¨“ç·´å¤±æ•— Stereo vision training failed: {str(e)}"
            self.log_message.emit(error_msg)
            self.log_message.emit(f"è©³ç´°éŒ¯èª¤ä¿¡æ¯ Detailed error traceback:")
            self.log_message.emit(error_detail)
            self.progress.emit("ç«‹é«”è¦–è¦ºè¨“ç·´å¤±æ•— Stereo vision training failed")
            raise e