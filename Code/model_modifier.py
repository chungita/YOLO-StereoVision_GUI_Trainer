"""
æ¨¡å‹ä¿®æ”¹å™¨æ¨¡çµ„
ç”¨æ–¼ä¿®æ”¹ PyTorch æ¨¡å‹çš„è¼¸å…¥é€šé“æ•¸ï¼Œæ”¯æŒæ–°å¢é€šé“åŠŸèƒ½
ä¿æŒåŸå§‹ç²¾åº¦ï¼Œä¸å¼·åˆ¶è½‰æ›ç‚ºfloat16
"""

import torch
import torch.nn as nn
from pathlib import Path
from typing import Optional, Dict, Any, Tuple
import logging

# è¨­ç½®æ—¥èªŒ
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)


class ModelModifier:
    """æ¨¡å‹ä¿®æ”¹å™¨ - èª¿æ•´ PyTorch æ¨¡å‹çš„è¼¸å…¥é€šé“æ•¸ï¼Œæ”¯æŒæ–°å¢é€šé“åŠŸèƒ½"""
    
    def __init__(self):
        """åˆå§‹åŒ–æ¨¡å‹ä¿®æ”¹å™¨"""
        self.supported_formats = ['.pt', '.pth']
        self.weight_methods = {
            'copy_avg': 'è¤‡è£½åŸå§‹æ¬Šé‡ + å¹³å‡å€¼',
            'copy_zero': 'è¤‡è£½åŸå§‹æ¬Šé‡ + é›¶åˆå§‹åŒ–',
            'copy_random': 'è¤‡è£½åŸå§‹æ¬Šé‡ + éš¨æ©Ÿåˆå§‹åŒ–',
            'full_random': 'å®Œå…¨éš¨æ©Ÿåˆå§‹åŒ–'
        }
    
    def analyze_model(self, model_path: str) -> Dict[str, Any]:
        """
        åˆ†ææ¨¡å‹çµæ§‹
        
        Args:
            model_path: æ¨¡å‹æ–‡ä»¶è·¯å¾‘
            
        Returns:
            æ¨¡å‹åˆ†æçµæœå­—å…¸
        """
        try:
            if not Path(model_path).exists():
                raise FileNotFoundError(f"æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {model_path}")
            
            logger.info("ğŸ” åˆ†ææ¨¡å‹çµæ§‹...")
            
            # è¼‰å…¥æ¨¡å‹
            model = torch.load(model_path, map_location='cpu', weights_only=False)
            
            # è™•ç†ä¸åŒçš„æ¨¡å‹æ ¼å¼
            if isinstance(model, dict):
                if 'model' in model:
                    model = model['model']
                elif 'state_dict' in model:
                    return {
                        'error': 'state_dict æ ¼å¼ä¸æ”¯æŒç›´æ¥åˆ†æ',
                        'model_type': 'state_dict',
                        'file_name': Path(model_path).name
                    }
            
            # åˆ†æç¬¬ä¸€å±¤å·ç©å±¤
            first_conv = None
            conv_layers = []
            
            for name, module in model.named_modules():
                if isinstance(module, torch.nn.Conv2d):
                    conv_info = {
                        'name': name,
                        'in_channels': module.in_channels,
                        'out_channels': module.out_channels,
                        'kernel_size': module.kernel_size,
                        'stride': module.stride,
                        'padding': module.padding,
                        'bias': module.bias is not None
                    }
                    conv_layers.append(conv_info)
                    
                    if first_conv is None:
                        first_conv = conv_info
            
            if first_conv is None:
                return {
                    'error': 'æœªæ‰¾åˆ°å·ç©å±¤',
                    'model_type': type(model).__name__,
                    'file_name': Path(model_path).name
                }
            
            # ç”Ÿæˆå»ºè­°
            suggestions = self._generate_suggestions(first_conv['in_channels'])
            
            return {
                'success': True,
                'file_name': Path(model_path).name,
                'model_type': type(model).__name__,
                'first_conv': first_conv,
                'all_conv_layers': conv_layers,
                'suggestions': suggestions,
                'total_conv_layers': len(conv_layers)
            }
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹åˆ†æå¤±æ•—: {e}")
            return {
                'error': f"æ¨¡å‹åˆ†æå¤±æ•—: {e}",
                'file_name': Path(model_path).name if model_path else "æœªçŸ¥"
            }
    
    
    def modify_model_channels(
        self, 
        input_path: str, 
        output_path: str = None, 
        original_channels: int = None, 
        target_channels: int = 4, 
        weight_method: str = 'copy_avg'
    ) -> Dict[str, Any]:
        """
        ä¿®æ”¹æ¨¡å‹é€šé“æ•¸
        
        Args:
            input_path: è¼¸å…¥æ¨¡å‹è·¯å¾‘
            output_path: è¼¸å‡ºæ¨¡å‹è·¯å¾‘ (å¯é¸ï¼Œé è¨­ç‚ºModel_file/4_channel/ç›®éŒ„)
            original_channels: åŸå§‹é€šé“æ•¸ (å¯é¸ï¼Œè‡ªå‹•æª¢æ¸¬)
            target_channels: ç›®æ¨™é€šé“æ•¸ (é è¨­ç‚º4)
            weight_method: æ¬Šé‡åˆå§‹åŒ–æ–¹æ³•
            
        Returns:
            ä¿®æ”¹çµæœå­—å…¸
        """
        try:
            if not Path(input_path).exists():
                raise FileNotFoundError(f"è¼¸å…¥æ¨¡å‹æ–‡ä»¶ä¸å­˜åœ¨: {input_path}")
            
            # è¼‰å…¥æ¨¡å‹ä»¥ç²å–åŸå§‹é€šé“æ•¸ï¼ˆå¦‚æœæœªæŒ‡å®šï¼‰
            model = torch.load(input_path, map_location='cpu', weights_only=False)
            if isinstance(model, dict) and 'model' in model:
                model = model['model']
            
            # è‡ªå‹•æª¢æ¸¬åŸå§‹é€šé“æ•¸
            if original_channels is None:
                for name, module in model.named_modules():
                    if isinstance(module, torch.nn.Conv2d):
                        original_channels = module.in_channels
                        break
                if original_channels is None:
                    raise Exception("æœªæ‰¾åˆ°å·ç©å±¤")
            
            if original_channels == target_channels:
                return {
                    'success': True,
                    'message': 'åŸå§‹é€šé“æ•¸èˆ‡ç›®æ¨™é€šé“æ•¸ç›¸åŒï¼Œç„¡éœ€ä¿®æ”¹',
                    'output_path': output_path
                }
            
            # å¦‚æœæ²’æœ‰æŒ‡å®šè¼¸å‡ºè·¯å¾‘ï¼Œè‡ªå‹•ç”Ÿæˆ
            if output_path is None:
                input_file = Path(input_path)
                # ç”Ÿæˆé è¨­è¼¸å‡ºè·¯å¾‘ï¼šModel_file/4_channel/åŸæœ¬æª”å_ç›®æ¨™é€šé“æ•¸channel.pt
                base_name = input_file.stem  # åŸæœ¬æª”åï¼ˆä¸å«å‰¯æª”åï¼‰
                output_filename = f"{base_name}_{target_channels}channel.pt"
                output_path = f"Model_file/4_channel/{output_filename}"
                
                # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
                Path("Model_file/4_channel").mkdir(parents=True, exist_ok=True)
            
            logger.info("ğŸ”§ é–‹å§‹ä¿®æ”¹æ¨¡å‹é€šé“æ•¸...")
            logger.info(f"   åŸå§‹é€šé“æ•¸: {original_channels}")
            logger.info(f"   ç›®æ¨™é€šé“æ•¸: {target_channels}")
            logger.info(f"   æ¬Šé‡åˆå§‹åŒ–: {self.weight_methods.get(weight_method, weight_method)}")
            logger.info(f"   è¼¸å‡ºè·¯å¾‘: {output_path}")
            
            # è¼‰å…¥æ¨¡å‹
            model = torch.load(input_path, map_location='cpu', weights_only=False)
            
            if isinstance(model, dict):
                if 'model' in model:
                    model = model['model']
                elif 'state_dict' in model:
                    raise Exception("state_dict æ ¼å¼ä¸æ”¯æŒç›´æ¥ä¿®æ”¹")
            
            # æ‰¾åˆ°ç¬¬ä¸€å±¤å·ç©å±¤
            first_conv = None
            first_conv_name = None
            
            for name, module in model.named_modules():
                if isinstance(module, torch.nn.Conv2d):
                    first_conv = module
                    first_conv_name = name
                    break
            
            if first_conv is None:
                raise Exception("æœªæ‰¾åˆ°å·ç©å±¤")
            
            if first_conv.in_channels != original_channels:
                raise Exception(f"æ¨¡å‹å¯¦éš›é€šé“æ•¸ ({first_conv.in_channels}) èˆ‡è¨­ç½®çš„åŸå§‹é€šé“æ•¸ ({original_channels}) ä¸åŒ¹é…")
            
            # å‰µå»ºæ–°çš„ç¬¬ä¸€å±¤å·ç©å±¤
            new_first_conv = nn.Conv2d(
                in_channels=target_channels,
                out_channels=first_conv.out_channels,
                kernel_size=first_conv.kernel_size,
                stride=first_conv.stride,
                padding=first_conv.padding,
                bias=first_conv.bias is not None
            )
            
            # ä¿æŒåŸå§‹ç²¾åº¦ï¼Œä¸å¼·åˆ¶è½‰æ›ç‚ºfloat16
            if first_conv.weight.dtype == torch.float16:
                new_first_conv = new_first_conv.half()
            else:
                new_first_conv = new_first_conv.float()
            
            # æ¬Šé‡åˆå§‹åŒ–
            self._initialize_weights(new_first_conv, first_conv, original_channels, target_channels, weight_method)
            
            # æ›¿æ›æ¨¡å‹ä¸­çš„ç¬¬ä¸€å±¤
            self._replace_first_conv(model, first_conv_name, new_first_conv)
            
            # æ›´æ–°æ¨¡å‹çš„yamlé…ç½®
            self._update_model_yaml(model, target_channels)
            
            # ä¿å­˜ä¿®æ”¹å¾Œçš„æ¨¡å‹
            torch.save(model, output_path)
            
            # é©—è­‰ä¿®æ”¹çµæœ
            verification_result = self._verify_modification(output_path, target_channels)
            
            file_size_mb = Path(output_path).stat().st_size / (1024 * 1024)
            
            return {
                'success': True,
                'message': 'æ¨¡å‹ä¿®æ”¹æˆåŠŸ',
                'output_path': output_path,
                'original_channels': original_channels,
                'target_channels': target_channels,
                'actual_channels': verification_result['actual_channels'],
                'weight_method': self.weight_methods.get(weight_method, weight_method),
                'file_size_mb': round(file_size_mb, 2),
                'yaml_updated': hasattr(model, 'yaml'),
                'verification': verification_result
            }
            
        except Exception as e:
            logger.error(f"âŒ æ¨¡å‹ä¿®æ”¹å¤±æ•—: {e}")
            return {
                'success': False,
                'error': f"æ¨¡å‹ä¿®æ”¹å¤±æ•—: {e}"
            }
    
    def _generate_suggestions(self, current_channels: int) -> Dict[str, Any]:
        """ç”Ÿæˆé€šé“æ•¸ä¿®æ”¹å»ºè­°"""
        suggestions = {
            'current_channels': current_channels,
            'recommended_target': None,
            'reason': None
        }
        
        if current_channels == 3:
            suggestions['recommended_target'] = 4
            suggestions['reason'] = 'æª¢æ¸¬åˆ°3é€šé“æ¨¡å‹ï¼Œå»ºè­°ä¿®æ”¹ç‚º4é€šé“ä»¥æ”¯æŒRGBDæ•¸æ“š'
        elif current_channels == 4:
            suggestions['recommended_target'] = 3
            suggestions['reason'] = 'æª¢æ¸¬åˆ°4é€šé“æ¨¡å‹ï¼Œå»ºè­°ä¿®æ”¹ç‚º3é€šé“ä»¥æ”¯æŒæ¨™æº–RGBæ•¸æ“š'
        else:
            suggestions['reason'] = f'ç•¶å‰{current_channels}é€šé“ï¼Œè«‹æ‰‹å‹•è¨­ç½®ç›®æ¨™é€šé“æ•¸'
        
        return suggestions
    
    def _initialize_weights(
        self, 
        new_conv: nn.Conv2d, 
        original_conv: nn.Conv2d, 
        original_channels: int, 
        target_channels: int, 
        weight_method: str
    ):
        """åˆå§‹åŒ–æ–°å·ç©å±¤çš„æ¬Šé‡"""
        with torch.no_grad():
            # ä¿æŒåŸå§‹ç²¾åº¦ï¼Œä¸å¼·åˆ¶è½‰æ›
            original_weight = original_conv.weight
            original_bias = original_conv.bias if original_conv.bias is not None else None
            
            if target_channels > original_channels:
                # å¢åŠ é€šé“æ•¸
                if weight_method.startswith('copy'):
                    # è¤‡è£½åŸå§‹æ¬Šé‡ï¼ˆä¿æŒåŸå§‹ç²¾åº¦ï¼‰
                    new_conv.weight[:, :original_channels, :, :] = original_weight
                    
                    if weight_method == 'copy_avg':
                        # æ–°é€šé“ä½¿ç”¨å¹³å‡å€¼
                        avg_weight = original_weight.mean(dim=1, keepdim=True)
                        new_conv.weight[:, original_channels:, :, :] = avg_weight
                    elif weight_method == 'copy_zero':
                        # æ–°é€šé“è¨­ç‚ºé›¶
                        new_conv.weight[:, original_channels:, :, :] = 0
                    elif weight_method == 'copy_random':
                        # æ–°é€šé“ä½¿ç”¨éš¨æ©Ÿåˆå§‹åŒ–
                        nn.init.xavier_uniform_(new_conv.weight[:, original_channels:, :, :])
                else:
                    # å®Œå…¨éš¨æ©Ÿåˆå§‹åŒ–
                    nn.init.xavier_uniform_(new_conv.weight)
            else:
                # æ¸›å°‘é€šé“æ•¸
                if weight_method.startswith('copy'):
                    # åªä¿ç•™å‰ target_channels å€‹é€šé“
                    new_conv.weight[:, :, :, :] = original_weight[:, :target_channels, :, :]
                else:
                    # å®Œå…¨éš¨æ©Ÿåˆå§‹åŒ–
                    nn.init.xavier_uniform_(new_conv.weight)
            
            # è™•ç†åç½®ï¼ˆä¿æŒåŸå§‹ç²¾åº¦ï¼‰
            if original_bias is not None:
                new_conv.bias = original_bias.clone()
    
    def _replace_first_conv(self, model: nn.Module, first_conv_name: str, new_conv: nn.Conv2d):
        """æ›¿æ›æ¨¡å‹ä¸­çš„ç¬¬ä¸€å±¤å·ç©å±¤"""
        for name, module in model.named_modules():
            if isinstance(module, torch.nn.Conv2d) and name == first_conv_name:
                # æ‰¾åˆ°çˆ¶æ¨¡å¡Šä¸¦æ›¿æ›
                parent_name = '.'.join(name.split('.')[:-1])
                if parent_name:
                    parent_module = model
                    for attr in parent_name.split('.'):
                        parent_module = getattr(parent_module, attr)
                    setattr(parent_module, name.split('.')[-1], new_conv)
                else:
                    # å¦‚æœç¬¬ä¸€å±¤æ˜¯æ ¹æ¨¡å¡Š
                    setattr(model, name, new_conv)
                break
    
    def _update_model_yaml(self, model, target_channels: int):
        """æ›´æ–°æ¨¡å‹çš„yamlé…ç½®ä»¥åæ˜ æ–°çš„é€šé“æ•¸"""
        try:
            import yaml
            
            # æª¢æŸ¥æ¨¡å‹æ˜¯å¦æœ‰yamlå±¬æ€§
            if not hasattr(model, 'yaml'):
                logger.info("æ¨¡å‹æ²’æœ‰yamlå±¬æ€§ï¼Œè·³éyamlæ›´æ–°ï¼ˆé€™æ˜¯æ­£å¸¸çš„ï¼Œå› ç‚ºæ¨™æº–PyTorchæ¨¡å‹ä¸åŒ…å«yamlé…ç½®ï¼‰")
                return
            
            # æª¢æŸ¥yamlå±¬æ€§æ˜¯å¦å¯è¨ªå•
            try:
                yaml_attr = getattr(model, 'yaml', None)
                if yaml_attr is None:
                    logger.info("æ¨¡å‹yamlå±¬æ€§ç‚ºNoneï¼Œè·³éyamlæ›´æ–°")
                    return
            except AttributeError as e:
                logger.info(f"ç„¡æ³•è¨ªå•æ¨¡å‹yamlå±¬æ€§: {e}ï¼Œè·³éyamlæ›´æ–°")
                return
            
            # å®‰å…¨åœ°è¨ªå•yamlå±¬æ€§
            try:
                yaml_content = model.yaml
            except AttributeError as e:
                logger.warning(f"ç„¡æ³•è¨ªå•æ¨¡å‹yamlå±¬æ€§: {e}ï¼Œè·³éyamlæ›´æ–°")
                return
            
            # å¦‚æœyamlæ˜¯å­—ç¬¦ä¸²ï¼Œè§£æç‚ºå­—å…¸
            if isinstance(yaml_content, str):
                try:
                    yaml_dict = yaml.safe_load(yaml_content)
                except Exception as e:
                    logger.warning(f"ç„¡æ³•è§£ææ¨¡å‹yamlå­—ç¬¦ä¸²: {e}")
                    return
            elif isinstance(yaml_content, dict):
                yaml_dict = yaml_content
            else:
                logger.warning(f"æœªçŸ¥çš„yamlæ ¼å¼: {type(yaml_content)}")
                return
            
            # æ›´æ–°é€šé“æ•¸ç›¸é—œé…ç½®
            if 'ch' in yaml_dict:
                yaml_dict['ch'] = target_channels
                logger.info(f"æ›´æ–°yamlé…ç½®: ch = {target_channels}")
            
            # æ›´æ–°backboneé…ç½®ä¸­çš„ç¬¬ä¸€å±¤é€šé“æ•¸
            if 'backbone' in yaml_dict and isinstance(yaml_dict['backbone'], list):
                for layer in yaml_dict['backbone']:
                    if isinstance(layer, list) and len(layer) >= 4:
                        # æª¢æŸ¥æ˜¯å¦æ˜¯ç¬¬ä¸€å±¤å·ç©å±¤
                        if layer[2] == 'Conv' and len(layer[3]) >= 2:
                            # æ›´æ–°ç¬¬ä¸€å±¤çš„è¼¸å…¥é€šé“æ•¸
                            layer[3][0] = target_channels
                            logger.info(f"æ›´æ–°backboneç¬¬ä¸€å±¤é€šé“æ•¸: {target_channels}")
                            break
            
            # å°‡æ›´æ–°å¾Œçš„é…ç½®è½‰æ›å›å­—ç¬¦ä¸²æ ¼å¼
            updated_yaml_str = yaml.dump(yaml_dict, default_flow_style=False)
            
            # å®‰å…¨åœ°è¨­ç½®yamlå±¬æ€§
            try:
                model.yaml = updated_yaml_str
                logger.info("æ¨¡å‹yamlé…ç½®å·²æ›´æ–°")
            except AttributeError as e:
                logger.warning(f"ç„¡æ³•è¨­ç½®æ¨¡å‹yamlå±¬æ€§: {e}")
            
        except Exception as e:
            logger.error(f"æ›´æ–°æ¨¡å‹yamlé…ç½®å¤±æ•—: {e}")
            # ä¸æ‹‹å‡ºç•°å¸¸ï¼Œå› ç‚ºyamlæ›´æ–°å¤±æ•—ä¸æ‡‰è©²é˜»æ­¢æ¨¡å‹ä¿®æ”¹
    
    
    def _verify_modification(self, output_path: str, expected_channels: int) -> Dict[str, Any]:
        """é©—è­‰ä¿®æ”¹çµæœ"""
        try:
            modified_model = torch.load(output_path, map_location='cpu', weights_only=False)
            if isinstance(modified_model, dict) and 'model' in modified_model:
                modified_model = modified_model['model']
            
            for name, module in modified_model.named_modules():
                if isinstance(module, torch.nn.Conv2d):
                    actual_channels = module.in_channels
                    return {
                        'success': True,
                        'actual_channels': actual_channels,
                        'expected_channels': expected_channels,
                        'match': actual_channels == expected_channels
                    }
            
            return {
                'success': False,
                'error': 'æœªæ‰¾åˆ°å·ç©å±¤é€²è¡Œé©—è­‰'
            }
            
        except Exception as e:
            return {
                'success': False,
                'error': f"é©—è­‰å¤±æ•—: {e}"
            }
    
    def get_weight_methods(self) -> Dict[str, str]:
        """ç²å–å¯ç”¨çš„æ¬Šé‡åˆå§‹åŒ–æ–¹æ³•"""
        return self.weight_methods.copy()
    
    def validate_model_file(self, model_path: str) -> bool:
        """é©—è­‰æ¨¡å‹æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ"""
        try:
            if not Path(model_path).exists():
                return False
            
            # å˜—è©¦è¼‰å…¥æ¨¡å‹
            model = torch.load(model_path, map_location='cpu', weights_only=False)
            
            # æª¢æŸ¥æ˜¯å¦åŒ…å«å·ç©å±¤
            has_conv = False
            if isinstance(model, dict):
                if 'model' in model:
                    model = model['model']
                elif 'state_dict' in model:
                    return False  # state_dict æ ¼å¼ä¸æ”¯æŒ
            
            for module in model.modules():
                if isinstance(module, torch.nn.Conv2d):
                    has_conv = True
                    break
            
            return has_conv
            
        except Exception:
            return False


def create_model_modifier() -> ModelModifier:
    """å‰µå»ºæ¨¡å‹ä¿®æ”¹å™¨å¯¦ä¾‹"""
    return ModelModifier()


# ä¾¿æ·å‡½æ•¸
def analyze_model_structure(model_path: str) -> Dict[str, Any]:
    """åˆ†ææ¨¡å‹çµæ§‹çš„ä¾¿æ·å‡½æ•¸"""
    modifier = ModelModifier()
    return modifier.analyze_model(model_path)




def modify_model_channels(
    input_path: str, 
    output_path: str = None, 
    original_channels: int = None, 
    target_channels: int = 4, 
    weight_method: str = 'copy_avg'
) -> Dict[str, Any]:
    """ä¿®æ”¹æ¨¡å‹é€šé“æ•¸çš„ä¾¿æ·å‡½æ•¸"""
    modifier = ModelModifier()
    return modifier.modify_model_channels(
        input_path, output_path, original_channels, target_channels, weight_method
    )


if __name__ == "__main__":
    # æ¸¬è©¦ä»£ç¢¼
    modifier = ModelModifier()
    
    # æ¸¬è©¦åˆ†æåŠŸèƒ½
    test_model = "Model_file/standard/yolov12n.pt"
    if Path(test_model).exists():
        print("=== æ¸¬è©¦æ¨¡å‹åˆ†æ ===")
        result = modifier.analyze_model(test_model)
        print("åˆ†æçµæœ:", result)
        
        
        print("\n=== æ¸¬è©¦é€šé“æ•¸ä¿®æ”¹ï¼ˆä½¿ç”¨é è¨­è·¯å¾‘ï¼‰===")
        channel_result = modifier.modify_model_channels(test_model, target_channels=4)
        print("é€šé“ä¿®æ”¹çµæœ:", channel_result)
    
    print("æ¨¡å‹ä¿®æ”¹å™¨æ¨¡çµ„è¼‰å…¥æˆåŠŸ")
